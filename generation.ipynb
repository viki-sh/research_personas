{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ScenarioGenerator class\n",
    "from generation import ScenarioGenerator\n",
    "from generation import update_for_cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the generator\n",
    "config = {\n",
    "    \"embedding_model\": \"all-MiniLM-L6-v2\",  # Lightweight model, good for 16GB RAM\n",
    "    \"similarity_threshold\": 0.85,  # Adjust based on desired uniqueness\n",
    "    \"batch_size\": 10,  # Number of scenarios to generate in parallel\n",
    "    \"max_workers\": 4,  # Set to half your CPU count for optimal performance\n",
    "    \"output_dir\": \"output\",\n",
    "    \"checkpoint_interval\": 5,  # Save progress every 25 unique scenarios\n",
    "    \"llm_provider\": \"cohere\"  # Change to \"openai\" if preferred\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usage in notebook\n",
    "generator = ScenarioGenerator(config)\n",
    "if config[\"llm_provider\"] == \"cohere\":\n",
    "    original_method = update_for_cohere(generator)\n",
    "generator.run_batch(1)\n",
    "# Analyze the results\n",
    "generator.analyze_results()\n",
    "\n",
    "# Restore original method if needed\n",
    "# generator.generate_scenario_text = original_method"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
